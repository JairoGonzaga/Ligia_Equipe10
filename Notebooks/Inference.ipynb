{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Importação e clonagem do git"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, recall_score, f1_score, confusion_matrix, roc_auc_score, \\\n",
    "    accuracy_score, roc_curve, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.preprocessing import prepare_data\n",
    "\n",
    "X_train, X_test, y_train, y_test, preprocessor = prepare_data(\"../Data/heart.csv\")\n",
    "from src.preprocessing import prepare_data\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Leitura dos Dados"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "X_test = pd.read_csv(\"../Data/X_test (1).csv\")\n",
    "Y_test = pd.read_csv(\"../Data/y_test (1).csv\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Carregamento do Modelo\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilizamos a biblioteca joblib porque o modelo foi estruturado como um objeto do scikit-learn (Pipeline). O joblib é a alternativa mais funcional para serializar esse tipo de objeto, permitindo salvar e carregar o modelo completo sem a necessidade de redefinir as etapas de pré-processamento."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "modelo = joblib.load(\"../Model/model.joblib\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Defina quantos pacientes você quer sortear\n",
    "n_pacientes = 5\n",
    "\n",
    "# 2. Sorteia os pacientes aleatórios do X_test\n",
    "amostra_pacientes = X_test.sample(n=n_pacientes)\n",
    "\n",
    "print(f\"--- ANALISANDO {n_pacientes} PACIENTES ALEATÓRIOS ---\\n\")\n",
    "\n",
    "# 3. Itera sobre a amostra\n",
    "for i in range(len(amostra_pacientes)):\n",
    "    # Pega uma linha da amostra\n",
    "    paciente = amostra_pacientes.iloc[i:i+1]\n",
    "    idx_original = amostra_pacientes.index[i]\n",
    "\n",
    "    # Inferência\n",
    "    pred = modelo.predict(paciente)[0]\n",
    "    prob = modelo.predict_proba(paciente)[0][1]\n",
    "\n",
    "    # Busca o valor real no Y_test usando o índice original\n",
    "    real = Y_test.loc[idx_original].item()\n",
    "\n",
    "    status = \"ACERTO\" if pred == real else \"ERRO\"\n",
    "\n",
    "    print(f\"ID Original: {idx_original} | Pred: {pred} | Real: {real} | Prob: {prob:.2%} | {status}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fizemos uma pequena análise de 5 pacientes aleatórios no intuito de testar a predição do nosso modelo. Foi identificado uma precisão nas predição em cerca  de 60%. Logo foi levado em conta uma maneira de contornar esse problema de integridade."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Novos dados gerados por I.A\n",
    "- Para verificar a integridade e a capacidade de generalização do modelo, geramos um conjunto de dados inéditos (não utilizados nas etapas de treinamento ou validação). Esses dados foram gerados sinteticamente com o auxílio do DeepSeek e submetidos ao modelo para validar a consistência das predições em cenários totalmente novos."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "pacientes = [\n",
    "    ({'Age':25, 'Sex':'M', 'ChestPainType':'NAP', 'RestingBP':110, 'Cholesterol':165,\n",
    "      'FastingBS':0, 'RestingECG':'Normal', 'MaxHR':195, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':0.2, 'ST_Slope':'Up'}, 0),\n",
    "\n",
    "    ({'Age':72, 'Sex':'F', 'ChestPainType':'ATA', 'RestingBP':185, 'Cholesterol':380,\n",
    "      'FastingBS':1, 'RestingECG':'LVH', 'MaxHR':95, 'ExerciseAngina':'Y',\n",
    "      'Oldpeak':4.8, 'ST_Slope':'Down'}, 1),\n",
    "\n",
    "    ({'Age':22, 'Sex':'F', 'ChestPainType':'NAP', 'RestingBP':105, 'Cholesterol':155,\n",
    "      'FastingBS':0, 'RestingECG':'Normal', 'MaxHR':190, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':0.1, 'ST_Slope':'Up'}, 0),\n",
    "\n",
    "    ({'Age':68, 'Sex':'M', 'ChestPainType':'ASY', 'RestingBP':170, 'Cholesterol':340,\n",
    "      'FastingBS':1, 'RestingECG':'ST', 'MaxHR':110, 'ExerciseAngina':'Y',\n",
    "      'Oldpeak':3.2, 'ST_Slope':'Flat'}, 1),\n",
    "\n",
    "    ({'Age':45, 'Sex':'M', 'ChestPainType':'NAP', 'RestingBP':125, 'Cholesterol':190,\n",
    "      'FastingBS':0, 'RestingECG':'Normal', 'MaxHR':165, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':0.8, 'ST_Slope':'Up'}, 0),\n",
    "\n",
    "    ({'Age':60, 'Sex':'F', 'ChestPainType':'ATA', 'RestingBP':155, 'Cholesterol':290,\n",
    "      'FastingBS':0, 'RestingECG':'LVH', 'MaxHR':130, 'ExerciseAngina':'Y',\n",
    "      'Oldpeak':2.5, 'ST_Slope':'Flat'}, 1),\n",
    "\n",
    "    ({'Age':50, 'Sex':'M', 'ChestPainType':'TA', 'RestingBP':135, 'Cholesterol':230,\n",
    "      'FastingBS':0, 'RestingECG':'Normal', 'MaxHR':155, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':1.0, 'ST_Slope':'Up'}, 0),\n",
    "\n",
    "    ({'Age':58, 'Sex':'F', 'ChestPainType':'ASY', 'RestingBP':150, 'Cholesterol':260,\n",
    "      'FastingBS':1, 'RestingECG':'ST', 'MaxHR':140, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':2.0, 'ST_Slope':'Flat'}, 1),\n",
    "\n",
    "    ({'Age':35, 'Sex':'M', 'ChestPainType':'ATA', 'RestingBP':145, 'Cholesterol':300,\n",
    "      'FastingBS':1, 'RestingECG':'Normal', 'MaxHR':160, 'ExerciseAngina':'Y',\n",
    "      'Oldpeak':1.8, 'ST_Slope':'Flat'}, 1),\n",
    "\n",
    "    ({'Age':70, 'Sex':'F', 'ChestPainType':'NAP', 'RestingBP':130, 'Cholesterol':200,\n",
    "      'FastingBS':0, 'RestingECG':'Normal', 'MaxHR':145, 'ExerciseAngina':'N',\n",
    "      'Oldpeak':0.9, 'ST_Slope':'Up'}, 0),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validação\n",
    "- Nessa parte, estamos usando os dados sinteticos gerados no modelo e verificando se estão corretos"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "acertos = 0\n",
    "\n",
    "for dados, esperado in pacientes:\n",
    "    previsao = modelo.predict(pd.DataFrame([dados]))[0]\n",
    "    acertou = (previsao == esperado)\n",
    "\n",
    "    print(f\"Paciente: {'SAUDÁVEL' if esperado==0 else 'DOENTE'}\")\n",
    "    print(f\"Previsao: {'SAUDÁVEL' if previsao==0 else 'DOENTE'}\")\n",
    "    print(f\"Resultado: {'Correto' if acertou else 'Errado'}\\n\")\n",
    "\n",
    "    y_true.append(esperado)\n",
    "    y_pred.append(previsao)\n",
    "\n",
    "    if acertou:\n",
    "        acertos += 1\n",
    "\n",
    "print(f\"Acertos: {acertos}/{len(pacientes)} ({acertos/len(pacientes):.0%})\")\n",
    "\n",
    "# Métricas e gráficos\n",
    "acuracia = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAcurácia: {acuracia:.2%}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Saudável', 'Doente']))\n",
    "\n",
    "# Gráfico de barras de acertos por classe\n",
    "acertos_por_classe = [sum((y_true[i] == 0) and (y_pred[i] == 0) for i in range(len(y_true))),\n",
    "                      sum((y_true[i] == 1) and (y_pred[i] == 1) for i in range(len(y_true)))]\n",
    "erros_por_classe = [sum((y_true[i] == 0) and (y_pred[i] == 1) for i in range(len(y_true))),\n",
    "                    sum((y_true[i] == 1) and (y_pred[i] == 0) for i in range(len(y_true)))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bar_width = 0.35\n",
    "index = range(2)\n",
    "\n",
    "bar1 = ax.bar(index, acertos_por_classe, bar_width, label='Acertos', color='green')\n",
    "bar2 = ax.bar([i + bar_width for i in index], erros_por_classe, bar_width, label='Erros', color='red')\n",
    "\n",
    "ax.set_xlabel('Classe')\n",
    "ax.set_ylabel('Quantidade')\n",
    "ax.set_title('Desempenho por Classe')\n",
    "ax.set_xticks([i + bar_width / 2 for i in index])\n",
    "ax.set_xticklabels(['Saudável', 'Doente'])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Após a adição de dados síntéticos, fizemos a validação do nosso modelo e analisamos o rendimento do nosso modelo por meio das seguintes métricas de validação: Precision, Recall, f1-score e support. E observamos os resultados com precisão em cerca de 100%, o que indica uma melhora do rendimento do nosso modelo após as alterações."
  }
 ]
}
